import torch
import torch.nn as nn
from torchvision import transforms, models
import cv2
import numpy as np
import requests
import time
from datetime import datetime
import os

# ‚úÖ Run headless (no GUI required)
os.environ["QT_QPA_PLATFORM"] = "offscreen"

try:
    from telegram_config import BOT_TOKEN, CHAT_ID, CONFIDENCE_THRESHOLD
except ImportError:
    BOT_TOKEN = None
    CHAT_ID = None
    CONFIDENCE_THRESHOLD = 0.8
    print("‚ö†Ô∏è Telegram config not found. Update telegram_config.py with your bot details.")


class AnimalDetector:
    def __init__(self, model_path='best_animal_model.pth'):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"üöÄ Loading model on: {self.device}")

        # Telegram setup
        self.bot_token = BOT_TOKEN
        self.chat_id = CHAT_ID
        self.confidence_threshold = CONFIDENCE_THRESHOLD
        self.last_sent_time = 0
        self.min_interval = 5  # Minimum 5 seconds between messages

        # Detection persistence tracking
        self.detection_start_time = None
        self.current_animal = None
        self.detection_duration = 5  # Require 5 seconds of detection

        # Load model checkpoint
        checkpoint = torch.load(model_path, map_location=self.device)

        # Handle class names
        if 'class_names' in checkpoint:
            self.class_names = checkpoint['class_names']
        else:
            self.class_names = ['Armadilles', 'Bear', 'Birds', 'Cow', 'Crocodile', 'Deer',
                                'Elephant', 'Goat', 'Horse', 'Jaguar', 'Monkey', 'Rabbit',
                                'Skunk', 'Tiger', 'Wild Boar']
            print("‚ö†Ô∏è Using default class names")

        print(f"üìã Classes: {self.class_names}")

        if 'accuracy' in checkpoint:
            print(f"üéØ Model accuracy: {checkpoint['accuracy']:.2%}")
        else:
            print("üìä Model accuracy: Not available")

        # Build model
        self.model = models.resnet50(weights=None)
        state_dict = checkpoint.get('model_state_dict', checkpoint)

        if 'fc.4.weight' in state_dict:
            self.model.fc = nn.Sequential(
                nn.Dropout(0.5),
                nn.Linear(self.model.fc.in_features, 512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, len(self.class_names))
            )
        else:
            self.model.fc = nn.Linear(self.model.fc.in_features, len(self.class_names))

        try:
            self.model.load_state_dict(state_dict)
            print("‚úÖ Model loaded successfully")
        except Exception as e:
            print(f"‚ùå Error loading model: {e}")
            print("üîß Trying ResNet34 fallback...")
            self.model = models.resnet34(weights=None)
            self.model.fc = nn.Linear(self.model.fc.in_features, len(self.class_names))
            self.model.load_state_dict(state_dict)
            print("‚úÖ Model loaded with ResNet34 architecture")

        self.model = self.model.to(self.device)
        self.model.eval()

        # Preprocessing
        self.transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406],
                                 [0.229, 0.224, 0.225])
        ])

        os.makedirs("detections", exist_ok=True)

    def predict_image(self, image_path):
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Could not load image: {image_path}")
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        input_tensor = self.transform(img_rgb).unsqueeze(0).to(self.device)
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
            confidence, predicted = torch.max(probabilities, 0)
        return self.class_names[predicted.item()], confidence.item()

    def send_to_telegram(self, frame, animal, confidence, duration):
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"detections/detection_{animal}_{confidence:.3f}_{timestamp}.jpg"
            cv2.imwrite(filename, frame)

            message = (
                f"üêæ *Animal Detected!*\n"
                f"üîç *Species:* {animal}\n"
                f"üìä *Confidence:* {confidence*100:.1f}%\n"
                f"‚è± *Time in frame:* {duration:.1f}s\n"
                f"üï∞ {datetime.now().strftime('%H:%M:%S')}"
            )

            # Print message to terminal as well
            print("\n" + "="*40)
            print(message.replace('*', ''))  # remove markdown for console clarity
            print("="*40 + "\n")

            if not self.bot_token or not self.chat_id:
                print("‚ö†Ô∏è Telegram not configured, skipping send")
                return

            url = f"https://api.telegram.org/bot{self.bot_token}/sendPhoto"
            with open(filename, 'rb') as photo:
                files = {'photo': photo}
                data = {'chat_id': self.chat_id, 'caption': message, 'parse_mode': 'Markdown'}
                response = requests.post(url, files=files, data=data, timeout=10)
                if response.status_code == 200:
                    print(f"üì§ Sent {animal} detection to Telegram")
                else:
                    print(f"‚ùå Telegram error: {response.status_code}")

        except Exception as e:
            print(f"‚ùå Telegram send error: {e}")

    def predict_webcam(self):
        # Try multiple camera backends
        cap = None
        for backend in [cv2.CAP_V4L2, cv2.CAP_GSTREAMER, cv2.CAP_ANY]:
            for i in range(3):
                print(f"Trying camera {i} with backend {backend}...")
                cap = cv2.VideoCapture(i, backend)
                if cap.isOpened():
                    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                    cap.set(cv2.CAP_PROP_FPS, 30)
                    time.sleep(2)
                    ret, test_frame = cap.read()
                    if ret and test_frame is not None:
                        print(f"‚úÖ Using camera {i} with backend {backend}")
                        break
                    else:
                        cap.release()
                        cap = None
            if cap and cap.isOpened():
                break

        if not cap or not cap.isOpened():
            print("‚ùå Could not open webcam.")
            print("üí° Try: sudo modprobe uvcvideo OR connect a USB camera.")
            return

        print("üìπ Headless webcam detection started (press Ctrl+C to stop)")

        while True:
            ret, frame = cap.read()
            if not ret:
                print("‚ùå Failed to read frame")
                break

            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            input_tensor = self.transform(frame_rgb).unsqueeze(0).to(self.device)

            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                confidence, predicted = torch.max(probabilities, 0)

            animal = self.class_names[predicted.item()]
            conf = confidence.item()
            current_time = time.time()

            # Detection logic
            if conf > self.confidence_threshold:
                if self.current_animal == animal:
                    duration = current_time - self.detection_start_time
                    print(f"‚è≥ {animal} ({conf*100:.1f}%) - in frame for {duration:.1f}s")
                    if duration >= self.detection_duration and (current_time - self.last_sent_time) > self.min_interval:
                        self.send_to_telegram(frame, animal, conf, duration)
                        self.last_sent_time = current_time
                        self.detection_start_time = current_time  # reset timer
                else:
                    self.current_animal = animal
                    self.detection_start_time = current_time
            else:
                self.current_animal = None
                self.detection_start_time = None

            time.sleep(0.5)

        cap.release()
        print("üìπ Webcam closed")


if __name__ == "__main__":
    try:
        detector = AnimalDetector()
        print("‚úÖ Model loaded successfully!")

        print("\nüé• Starting headless webcam detection...")
        if detector.bot_token and detector.chat_id:
            print(f"ü§ñ Telegram bot enabled - will send photos when confidence > {detector.confidence_threshold:.0%}")
        else:
            print("‚ö†Ô∏è Telegram not configured - update telegram_config.py")

        detector.predict_webcam()

    except FileNotFoundError:
        print("‚ùå Model file 'best_animal_model.pth' not found!")
    except KeyboardInterrupt:
        print("\nüõë Stopped by user.")
    except Exception as e:
        print(f"‚ùå Error: {e}")
